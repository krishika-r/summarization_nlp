{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17899,"status":"ok","timestamp":1688033240873,"user":{"displayName":"Krishika Ragunathan","userId":"01566786126154607843"},"user_tz":-330},"id":"E1zeTxc6UibD","outputId":"736ad26d-2e23-46a3-c2fd-9a3eb65e5f6e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["#Mount drive\n","from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1688033240875,"user":{"displayName":"Krishika Ragunathan","userId":"01566786126154607843"},"user_tz":-330},"id":"IwHjgwvWUk55","outputId":"11f7656f-8a7d-4f7e-a1ae-ad38688a3a30"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/table_text_summarization_package\n"]}],"source":["%cd /content/drive/MyDrive/table_text_summarization_package/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ub4u0W4syG9W"},"outputs":[],"source":["!pip install -r requirements.txt\n","!pip install --upgrade accelerate"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"sUHKle8wVF6a"},"source":["## **Imports and Initializations**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EWTXJeWyGDCg"},"outputs":[],"source":["from table_text_summarization import Summarizer\n","from helper import get_evaluation_metrics\n","import os\n","import pandas as pd\n","import json"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"t0tPZpBTKHKZ"},"source":["# **Table-To-Insights**\n","\n","The objective of the solution notebook is to demonstrate how to use summarization module from Tiger-NLP ðŸ¯ for Finetuning and Inferencing table-to-insight objective.\n","\n","\n","\n","*   **Table-to-Insights** : The model has to generate insight/summary of a table which is converted into a free flowing text and passed as input sequence.\n","\n","We will see how to easily load and preprocess the dataset for the task, and how to use the Trainer API to train a model on it. We will also demonstrate how to inference a dataset incase you already have a trained model.\n","\n","The trainer/inference module is based on pytorch framework and can leverage GPU accelerated machine for training/inferencing.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gomwLyivGMWk"},"outputs":[],"source":["# Initializing Summarizer object for table-to-insight task\n","# summary_type = \"table\" triggers pre processing functions required for processing tabular data.\n","model = Summarizer(summary_type=\"table\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"bVXb8CJjofxY"},"source":["## **Preprocessing the data**\n","\n","The preprocessing step involves conversion of tables/dataframes present in csv or excels into free flowing text and is saved as JSONs for model training/inferencing.\n","\n"," - **Example folder structure and file type of raw data**\n","```\n","|-- train_folder/\n","|   |-- table_1.csv\n","|   |-- table_1.jsonl\n","|   |-- table_2.csv\n","|   |-- table_2.jsonl\n","|    ...\n","|    ...\n","|   |-- table_n.csv\n","|   |-- table_n.jsonl\n","```\n","\n","  -> **.csv** - Contains the table in structured format which needs to be processed to flattened text\n","\n","  -> **.jsonl** - Contains two fields which is Summary and Highlighted cells.\n","  e.g.\n","```\n","{summary : \"actual summary of the data\", highlighted_cells : [[1,2],[2,2],[3,2]]}\n","```\n","   - Summary represents the actual summary of the table which will be used for model training.\n","   - Highlighted cells represents the cells for which the summary is available or want to generate during inference.\n","\n","   In the above example, `highlighted cells: [[1,2],[2,2],[3,2]]` specify the pre-process function to select data only in rows 1,2,3 and column 2 from the table and `summary: \"actual summary of the data\"` will have the actual summary of these 3 rows\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_w33RKUIXjHw","outputId":"61f252a5-6450-4c91-f6ae-11ad91864030"},"outputs":[{"name":"stdout","output_type":"stream","text":["actual summary\n","[[1, 0], [1, 1], [1, 2]]\n","Executed Lattice...\n","Pre-processing done...\n"]}],"source":["# model.pre_process() is used to pre process tables into flattened text\n","# `data` argument is the folder path of the data\n","# `data_type` argument specifies the type of the data for model training\n","model.pre_process(data_path='data/train_folder',data_type='train')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R5yTVOd-XjWw","outputId":"9d9cbcd2-7dba-4993-9770-e060af450802"},"outputs":[{"name":"stdout","output_type":"stream","text":["Executed Lattice...\n","Pre-processing done...\n"]}],"source":["model.pre_process(data_path=\"data/test_folder\",data_type='test')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UU7rsHE6Xuml","outputId":"009f15c9-b42d-437b-f7fa-466f44620efd"},"outputs":[{"name":"stdout","output_type":"stream","text":["validation data table summary\n","[[1, 0], [1, 1], [1, 2], [1, 3], [1, 4]]\n","Executed Lattice...\n","Pre-processing done...\n"]}],"source":["model.pre_process(data_path=\"data/validation_folder\",data_type='validation')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"I6WG92zhpckk"},"source":["## **Fine-tuning the model**\n","\n","Now that our data is ready, we can download the pretrained model and fine-tune it. Since our task is of the sequence-to-sequence kind, we use the AutoModelForSeq2SeqLM class internally. Like with the tokenizer, the from_pretrained method will download and cache the model for us.\n","\n","We can use pretrained-model from huggingface and it supports Seq2Seq architectures. e.g. T5, BART, GPT etc.\n","\n","Below mentioned are some of the important points :\n","\n","* The user should provide the training and validation file path(optional) in **json/csv format**. The text column name should be **\"text\"** and summary column name should be **\"summary\"**\n","\n","* The user should also provide the output path where all the model results will be saved.\n","\n","* If the model name is not specified, default model(**facebook/bart-large-cnn**) is taken into consideration\n","\n","* If the model is t5  specifiy **model type =t5**, so that t5 params will get considered. else **model type = others**\n","\n","* Default model params are considered for the architecture specified. We can pass [**kwargs](https://huggingface.co/transformers/v3.0.2/main_classes/trainer.html#trainingarguments) to the train function to alter the default model params.\n","\n","* The user should provide **train_prediction = True** for train data prediction and **val_prediction = True** for validation data prediction.\n","\n","* **Train/validation** and **eval metrics** are stored in **prediction folder** inside output folder path.\n","```\n","|--output_path/\n","|    |--prediction folder/\n","|       |-- train folder/\n","|          |--train_data_benchmarks.csv\n","|          |--train_generated_predictions.jsonl\n","|       |--validation folder/\n","|          |--validation_data_benchmarks.csv\n","|          |--validation_generated_predictions.jsonl\n","```\n","\n","\n","For more information the user can refer [HuggingFace Summarization](https://github.com/huggingface/transformers/tree/main/examples/pytorch/summarization)\n","\n","**NOTE**: When **output_path='table'** then fine-tuned model is saved in **'table/training'** folder"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RSfCgKTLz0J7","outputId":"11cdd994-8664-4b36-a2e9-98546bc71bf0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Executed\n","Model Name: t5-small\n","validation\n","training started\n","Trainer output:  b\"05/05/2023 07:34:10 - WARNING - __main__ - Process rank: 0, device: cpu, n_gpu: 0distributed training: True, 16-bits training: False\\n05/05/2023 07:34:10 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\\n_n_gpu=0,\\nadafactor=False,\\nadam_beta1=0.9,\\nadam_beta2=0.999,\\nadam_epsilon=1e-08,\\nauto_find_batch_size=False,\\nbf16=False,\\nbf16_full_eval=False,\\ndata_seed=None,\\ndataloader_drop_last=False,\\ndataloader_num_workers=0,\\ndataloader_pin_memory=True,\\nddp_backend=None,\\nddp_bucket_cap_mb=None,\\nddp_find_unused_parameters=None,\\nddp_timeout=1800,\\ndebug=[],\\ndeepspeed=None,\\ndisable_tqdm=False,\\ndo_eval=True,\\ndo_predict=False,\\ndo_train=True,\\neval_accumulation_steps=None,\\neval_delay=0,\\neval_steps=None,\\nevaluation_strategy=no,\\nfp16=False,\\nfp16_backend=auto,\\nfp16_full_eval=False,\\nfp16_opt_level=O1,\\nfsdp=[],\\nfsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\\nfsdp_min_num_params=0,\\nfsdp_transformer_layer_cls_to_wrap=None,\\nfull_determinism=False,\\ngeneration_config=None,\\ngeneration_max_length=None,\\ngeneration_num_beams=None,\\ngradient_accumulation_steps=1,\\ngradient_checkpointing=False,\\ngreater_is_better=None,\\ngroup_by_length=False,\\nhalf_precision_backend=auto,\\nhub_model_id=None,\\nhub_private_repo=False,\\nhub_strategy=every_save,\\nhub_token=<HUB_TOKEN>,\\nignore_data_skip=False,\\ninclude_inputs_for_metrics=False,\\njit_mode_eval=False,\\nlabel_names=None,\\nlabel_smoothing_factor=0.0,\\nlearning_rate=3e-05,\\nlength_column_name=length,\\nload_best_model_at_end=False,\\nlocal_rank=0,\\nlog_level=passive,\\nlog_level_replica=warning,\\nlog_on_each_node=True,\\nlogging_dir=table/training/runs/May05_07-34-10_02be5ec3e31f,\\nlogging_first_step=False,\\nlogging_nan_inf_filter=True,\\nlogging_steps=500,\\nlogging_strategy=steps,\\nlr_scheduler_type=linear,\\nmax_grad_norm=1.0,\\nmax_steps=-1,\\nmetric_for_best_model=None,\\nmp_parameters=,\\nno_cuda=False,\\nnum_train_epochs=3.0,\\noptim=adamw_hf,\\noptim_args=None,\\noutput_dir=table/training,\\noverwrite_output_dir=True,\\npast_index=-1,\\nper_device_eval_batch_size=4,\\nper_device_train_batch_size=4,\\npredict_with_generate=True,\\nprediction_loss_only=False,\\npush_to_hub=False,\\npush_to_hub_model_id=None,\\npush_to_hub_organization=None,\\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\\nray_scope=last,\\nremove_unused_columns=True,\\nreport_to=['tensorboard'],\\nresume_from_checkpoint=None,\\nrun_name=table/training,\\nsave_on_each_node=False,\\nsave_safetensors=False,\\nsave_steps=500,\\nsave_strategy=steps,\\nsave_total_limit=None,\\nseed=42,\\nsharded_ddp=[],\\nskip_memory_metrics=True,\\nsortish_sampler=False,\\ntf32=None,\\ntorch_compile=False,\\ntorch_compile_backend=None,\\ntorch_compile_mode=None,\\ntorchdynamo=None,\\ntpu_metrics_debug=False,\\ntpu_num_cores=None,\\nuse_ipex=False,\\nuse_legacy_prediction_loop=False,\\nuse_mps_device=False,\\nwarmup_ratio=0.0,\\nwarmup_steps=0,\\nweight_decay=0.0,\\nxpu_backend=None,\\n)\\n05/05/2023 07:34:10 - INFO - datasets.builder - Using custom data configuration default-ba1710215b7f760b\\n05/05/2023 07:34:10 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\\n05/05/2023 07:34:10 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\\n05/05/2023 07:34:10 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-ba1710215b7f760b/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\n05/05/2023 07:34:10 - WARNING - datasets.builder - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-ba1710215b7f760b/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\\n05/05/2023 07:34:10 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-ba1710215b7f760b/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\n05/05/2023 07:34:12 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-ba1710215b7f760b/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-b57e0e7521de5ed1.arrow\\n05/05/2023 07:34:12 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-ba1710215b7f760b/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-0825931157dae195.arrow\\n{'train_runtime': 5.1503, 'train_samples_per_second': 1.165, 'train_steps_per_second': 0.582, 'train_loss': 8.86822255452474, 'epoch': 3.0}\\n***** train metrics *****\\n  epoch                    =        3.0\\n  train_loss               =     8.8682\\n  train_runtime            = 0:00:05.15\\n  train_samples            =          2\\n  train_samples_per_second =      1.165\\n  train_steps_per_second   =      0.582\\n05/05/2023 07:34:19 - INFO - __main__ - *** Evaluate ***\\n***** eval metrics *****\\n  epoch                   =        3.0\\n  eval_gen_len            =      114.0\\n  eval_loss               =     7.6392\\n  eval_rouge1             =     5.2632\\n  eval_rouge2             =        0.0\\n  eval_rougeL             =     5.2632\\n  eval_rougeLsum          =     5.2632\\n  eval_runtime            = 0:00:04.40\\n  eval_samples            =          1\\n  eval_samples_per_second =      0.227\\n  eval_steps_per_second   =      0.227\\n\"\n","train prediction\n","Evaluation output:  b\"05/05/2023 07:34:32 - WARNING - __main__ - Process rank: 0, device: cpu, n_gpu: 0distributed training: True, 16-bits training: False\\n05/05/2023 07:34:32 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\\n_n_gpu=0,\\nadafactor=False,\\nadam_beta1=0.9,\\nadam_beta2=0.999,\\nadam_epsilon=1e-08,\\nauto_find_batch_size=False,\\nbf16=False,\\nbf16_full_eval=False,\\ndata_seed=None,\\ndataloader_drop_last=False,\\ndataloader_num_workers=0,\\ndataloader_pin_memory=True,\\nddp_backend=None,\\nddp_bucket_cap_mb=None,\\nddp_find_unused_parameters=None,\\nddp_timeout=1800,\\ndebug=[],\\ndeepspeed=None,\\ndisable_tqdm=False,\\ndo_eval=False,\\ndo_predict=True,\\ndo_train=False,\\neval_accumulation_steps=None,\\neval_delay=0,\\neval_steps=None,\\nevaluation_strategy=no,\\nfp16=False,\\nfp16_backend=auto,\\nfp16_full_eval=False,\\nfp16_opt_level=O1,\\nfsdp=[],\\nfsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\\nfsdp_min_num_params=0,\\nfsdp_transformer_layer_cls_to_wrap=None,\\nfull_determinism=False,\\ngeneration_config=None,\\ngeneration_max_length=None,\\ngeneration_num_beams=None,\\ngradient_accumulation_steps=1,\\ngradient_checkpointing=False,\\ngreater_is_better=None,\\ngroup_by_length=False,\\nhalf_precision_backend=auto,\\nhub_model_id=None,\\nhub_private_repo=False,\\nhub_strategy=every_save,\\nhub_token=<HUB_TOKEN>,\\nignore_data_skip=False,\\ninclude_inputs_for_metrics=False,\\njit_mode_eval=False,\\nlabel_names=None,\\nlabel_smoothing_factor=0.0,\\nlearning_rate=3e-05,\\nlength_column_name=length,\\nload_best_model_at_end=False,\\nlocal_rank=0,\\nlog_level=passive,\\nlog_level_replica=warning,\\nlog_on_each_node=True,\\nlogging_dir=table/prediction/runs/May05_07-34-32_02be5ec3e31f,\\nlogging_first_step=False,\\nlogging_nan_inf_filter=True,\\nlogging_steps=500,\\nlogging_strategy=steps,\\nlr_scheduler_type=linear,\\nmax_grad_norm=1.0,\\nmax_steps=-1,\\nmetric_for_best_model=None,\\nmp_parameters=,\\nno_cuda=False,\\nnum_train_epochs=3.0,\\noptim=adamw_hf,\\noptim_args=None,\\noutput_dir=table/prediction,\\noverwrite_output_dir=True,\\npast_index=-1,\\nper_device_eval_batch_size=4,\\nper_device_train_batch_size=4,\\npredict_with_generate=True,\\nprediction_loss_only=False,\\npush_to_hub=False,\\npush_to_hub_model_id=None,\\npush_to_hub_organization=None,\\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\\nray_scope=last,\\nremove_unused_columns=True,\\nreport_to=['tensorboard'],\\nresume_from_checkpoint=None,\\nrun_name=table/prediction,\\nsave_on_each_node=False,\\nsave_safetensors=False,\\nsave_steps=500,\\nsave_strategy=steps,\\nsave_total_limit=None,\\nseed=42,\\nsharded_ddp=[],\\nskip_memory_metrics=True,\\nsortish_sampler=False,\\ntf32=None,\\ntorch_compile=False,\\ntorch_compile_backend=None,\\ntorch_compile_mode=None,\\ntorchdynamo=None,\\ntpu_metrics_debug=False,\\ntpu_num_cores=None,\\nuse_ipex=False,\\nuse_legacy_prediction_loop=False,\\nuse_mps_device=False,\\nwarmup_ratio=0.0,\\nwarmup_steps=0,\\nweight_decay=0.0,\\nxpu_backend=None,\\n)\\n05/05/2023 07:34:32 - INFO - datasets.builder - Using custom data configuration default-f3e0d63b25626a1e\\n05/05/2023 07:34:32 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\\n05/05/2023 07:34:32 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\\n05/05/2023 07:34:32 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-f3e0d63b25626a1e/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\n05/05/2023 07:34:32 - WARNING - datasets.builder - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-f3e0d63b25626a1e/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\\n05/05/2023 07:34:32 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-f3e0d63b25626a1e/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\n05/05/2023 07:34:33 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-f3e0d63b25626a1e/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-bef8621bae2532e4.arrow\\n05/05/2023 07:34:33 - INFO - __main__ - *** Predict ***\\n***** predict metrics *****\\n  predict_gen_len            =      114.0\\n  predict_loss               =     9.2287\\n  predict_rouge1             =        0.0\\n  predict_rouge2             =        0.0\\n  predict_rougeL             =        0.0\\n  predict_rougeLsum          =        0.0\\n  predict_runtime            = 0:00:06.30\\n  predict_samples            =          2\\n  predict_samples_per_second =      0.317\\n  predict_steps_per_second   =      0.159\\n\"\n","val prediction\n","Evaluation output:  b\"05/05/2023 07:34:48 - WARNING - __main__ - Process rank: 0, device: cpu, n_gpu: 0distributed training: True, 16-bits training: False\\n05/05/2023 07:34:48 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\\n_n_gpu=0,\\nadafactor=False,\\nadam_beta1=0.9,\\nadam_beta2=0.999,\\nadam_epsilon=1e-08,\\nauto_find_batch_size=False,\\nbf16=False,\\nbf16_full_eval=False,\\ndata_seed=None,\\ndataloader_drop_last=False,\\ndataloader_num_workers=0,\\ndataloader_pin_memory=True,\\nddp_backend=None,\\nddp_bucket_cap_mb=None,\\nddp_find_unused_parameters=None,\\nddp_timeout=1800,\\ndebug=[],\\ndeepspeed=None,\\ndisable_tqdm=False,\\ndo_eval=False,\\ndo_predict=True,\\ndo_train=False,\\neval_accumulation_steps=None,\\neval_delay=0,\\neval_steps=None,\\nevaluation_strategy=no,\\nfp16=False,\\nfp16_backend=auto,\\nfp16_full_eval=False,\\nfp16_opt_level=O1,\\nfsdp=[],\\nfsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\\nfsdp_min_num_params=0,\\nfsdp_transformer_layer_cls_to_wrap=None,\\nfull_determinism=False,\\ngeneration_config=None,\\ngeneration_max_length=None,\\ngeneration_num_beams=None,\\ngradient_accumulation_steps=1,\\ngradient_checkpointing=False,\\ngreater_is_better=None,\\ngroup_by_length=False,\\nhalf_precision_backend=auto,\\nhub_model_id=None,\\nhub_private_repo=False,\\nhub_strategy=every_save,\\nhub_token=<HUB_TOKEN>,\\nignore_data_skip=False,\\ninclude_inputs_for_metrics=False,\\njit_mode_eval=False,\\nlabel_names=None,\\nlabel_smoothing_factor=0.0,\\nlearning_rate=3e-05,\\nlength_column_name=length,\\nload_best_model_at_end=False,\\nlocal_rank=0,\\nlog_level=passive,\\nlog_level_replica=warning,\\nlog_on_each_node=True,\\nlogging_dir=table/prediction/validation/runs/May05_07-34-48_02be5ec3e31f,\\nlogging_first_step=False,\\nlogging_nan_inf_filter=True,\\nlogging_steps=500,\\nlogging_strategy=steps,\\nlr_scheduler_type=linear,\\nmax_grad_norm=1.0,\\nmax_steps=-1,\\nmetric_for_best_model=None,\\nmp_parameters=,\\nno_cuda=False,\\nnum_train_epochs=3.0,\\noptim=adamw_hf,\\noptim_args=None,\\noutput_dir=table/prediction/validation,\\noverwrite_output_dir=True,\\npast_index=-1,\\nper_device_eval_batch_size=4,\\nper_device_train_batch_size=4,\\npredict_with_generate=True,\\nprediction_loss_only=False,\\npush_to_hub=False,\\npush_to_hub_model_id=None,\\npush_to_hub_organization=None,\\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\\nray_scope=last,\\nremove_unused_columns=True,\\nreport_to=['tensorboard'],\\nresume_from_checkpoint=None,\\nrun_name=table/prediction/validation,\\nsave_on_each_node=False,\\nsave_safetensors=False,\\nsave_steps=500,\\nsave_strategy=steps,\\nsave_total_limit=None,\\nseed=42,\\nsharded_ddp=[],\\nskip_memory_metrics=True,\\nsortish_sampler=False,\\ntf32=None,\\ntorch_compile=False,\\ntorch_compile_backend=None,\\ntorch_compile_mode=None,\\ntorchdynamo=None,\\ntpu_metrics_debug=False,\\ntpu_num_cores=None,\\nuse_ipex=False,\\nuse_legacy_prediction_loop=False,\\nuse_mps_device=False,\\nwarmup_ratio=0.0,\\nwarmup_steps=0,\\nweight_decay=0.0,\\nxpu_backend=None,\\n)\\n05/05/2023 07:34:48 - INFO - datasets.builder - Using custom data configuration default-7a27395613cee76c\\n05/05/2023 07:34:48 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\\n05/05/2023 07:34:48 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\\n05/05/2023 07:34:48 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-7a27395613cee76c/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\n05/05/2023 07:34:48 - WARNING - datasets.builder - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-7a27395613cee76c/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\\n05/05/2023 07:34:48 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-7a27395613cee76c/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\n05/05/2023 07:34:49 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-7a27395613cee76c/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-da6effc996eb3a41.arrow\\n05/05/2023 07:34:50 - INFO - __main__ - *** Predict ***\\n***** predict metrics *****\\n  predict_gen_len            =      114.0\\n  predict_loss               =     7.8686\\n  predict_rouge1             =     5.2632\\n  predict_rouge2             =        0.0\\n  predict_rougeL             =     5.2632\\n  predict_rougeLsum          =     5.2632\\n  predict_runtime            = 0:00:03.95\\n  predict_samples            =          1\\n  predict_samples_per_second =      0.253\\n  predict_steps_per_second   =      0.253\\n\"\n"]}],"source":["# model.train() function is used for fine tunning\n","# `train_data_path` :\n","# `output_path` :\n","# `model_name` :\n","# `model_type` :\n","# `train_prediction` :\n","# `val_prediction` :\n","# `valn_path` :\n","# **kwargs : Additional arguments for the models\n","\n","# Using trainer function with necessary params\n","model.train(train_data_path=\"data/train_folder/processed/train_data.json\",output_path=\"table\", model_name=\"t5-small\",model_type=\"t5\",valn_path=\"data/validation_folder/processed/validation_data.json\")\n","\n","# Using trainer function with additional params\n","# model.train(train_data_path=\"data/train_folder/processed/train_data.json\",output_path=\"table\", model_name=\"t5-small\",model_type=\"t5\",valn_path=\"data/validation_folder/processed/validation_data.json\",train_prediction=True,val_prediction=True,per_device_train_batch_size=2,learning_rate=5e-5,max_train_samples=50)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"15n8rxR3caRR"},"source":["## **Inferencing the model**\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"dFn_NQRCmjsu"},"source":["### **Using test data**\n","\n","See the up-to-date list of [available models](https://huggingface.co/models?pipeline_tag=summarization)\n","\n","Below mentioned are some of the important points :\n","\n","* The user should provide the test path in  **json/csv format**. The text column name should be **\"text\"**\n","\n","* The user should also provide the output path where all the model results will be saved.\n","\n","* We can pass pretrained / fine tuned model path. If the model name is not specified, default model(**facebook/bart-large-cnn**) is taken into consideration\n","\n","* If the model is t5  specifiy **model type =t5**, so that t5 params will get considered. else **model type = others**\n","\n","We can pass [**kwargs](https://huggingface.co/transformers/v3.0.2/main_classes/trainer.html#trainingarguments) to the predict function to alter the default model params.\n","\n","(i.e) test_data_benchmarks.csv(optional -it generates only if test data has actual summary)\n","\n","* **Train/validation/test prediction** and **eval metrics** are stored in **prediction folder** inside output folder path.\n","```\n","|--output_path/\n","|    |--prediction folder/\n","|       |-- train folder/\n","|          |--train_data_benchmarks.csv\n","|          |--train_generated_predictions.jsonl\n","|       |--validation folder/\n","|          |--validation_data_benchmarks.csv\n","|          |--validation_generated_predictions.jsonl\n","|       |--test folder/\n","|          |--test_data_benchmarks.csv\n","|          |--test_generated_predictions.jsonl\n","```"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"kYidoIu7wtkD"},"source":["#### **Pretrained model**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OqO5duDSZ39T","outputId":"1177abf3-ebdb-41c1-9eea-4ecef800d236"},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluation output:  b\"05/05/2023 06:10:04 - WARNING - __main__ - Process rank: 0, device: cpu, n_gpu: 0distributed training: True, 16-bits training: False\\n05/05/2023 06:10:04 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\\n_n_gpu=0,\\nadafactor=False,\\nadam_beta1=0.9,\\nadam_beta2=0.999,\\nadam_epsilon=1e-08,\\nauto_find_batch_size=False,\\nbf16=False,\\nbf16_full_eval=False,\\ndata_seed=None,\\ndataloader_drop_last=False,\\ndataloader_num_workers=0,\\ndataloader_pin_memory=True,\\nddp_backend=None,\\nddp_bucket_cap_mb=None,\\nddp_find_unused_parameters=None,\\nddp_timeout=1800,\\ndebug=[],\\ndeepspeed=None,\\ndisable_tqdm=False,\\ndo_eval=False,\\ndo_predict=True,\\ndo_train=False,\\neval_accumulation_steps=None,\\neval_delay=0,\\neval_steps=None,\\nevaluation_strategy=no,\\nfp16=False,\\nfp16_backend=auto,\\nfp16_full_eval=False,\\nfp16_opt_level=O1,\\nfsdp=[],\\nfsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\\nfsdp_min_num_params=0,\\nfsdp_transformer_layer_cls_to_wrap=None,\\nfull_determinism=False,\\ngeneration_config=None,\\ngeneration_max_length=None,\\ngeneration_num_beams=None,\\ngradient_accumulation_steps=1,\\ngradient_checkpointing=False,\\ngreater_is_better=None,\\ngroup_by_length=False,\\nhalf_precision_backend=auto,\\nhub_model_id=None,\\nhub_private_repo=False,\\nhub_strategy=every_save,\\nhub_token=<HUB_TOKEN>,\\nignore_data_skip=False,\\ninclude_inputs_for_metrics=False,\\njit_mode_eval=False,\\nlabel_names=None,\\nlabel_smoothing_factor=0.0,\\nlearning_rate=3e-05,\\nlength_column_name=length,\\nload_best_model_at_end=False,\\nlocal_rank=0,\\nlog_level=passive,\\nlog_level_replica=warning,\\nlog_on_each_node=True,\\nlogging_dir=table/prediction/test/runs/May05_06-10-03_02be5ec3e31f,\\nlogging_first_step=False,\\nlogging_nan_inf_filter=True,\\nlogging_steps=500,\\nlogging_strategy=steps,\\nlr_scheduler_type=linear,\\nmax_grad_norm=1.0,\\nmax_steps=-1,\\nmetric_for_best_model=None,\\nmp_parameters=,\\nno_cuda=False,\\nnum_train_epochs=3.0,\\noptim=adamw_hf,\\noptim_args=None,\\noutput_dir=table/prediction/test,\\noverwrite_output_dir=True,\\npast_index=-1,\\nper_device_eval_batch_size=4,\\nper_device_train_batch_size=4,\\npredict_with_generate=True,\\nprediction_loss_only=False,\\npush_to_hub=False,\\npush_to_hub_model_id=None,\\npush_to_hub_organization=None,\\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\\nray_scope=last,\\nremove_unused_columns=True,\\nreport_to=['tensorboard'],\\nresume_from_checkpoint=None,\\nrun_name=table/prediction/test,\\nsave_on_each_node=False,\\nsave_safetensors=False,\\nsave_steps=500,\\nsave_strategy=steps,\\nsave_total_limit=None,\\nseed=42,\\nsharded_ddp=[],\\nskip_memory_metrics=True,\\nsortish_sampler=False,\\ntf32=None,\\ntorch_compile=False,\\ntorch_compile_backend=None,\\ntorch_compile_mode=None,\\ntorchdynamo=None,\\ntpu_metrics_debug=False,\\ntpu_num_cores=None,\\nuse_ipex=False,\\nuse_legacy_prediction_loop=False,\\nuse_mps_device=False,\\nwarmup_ratio=0.0,\\nwarmup_steps=0,\\nweight_decay=0.0,\\nxpu_backend=None,\\n)\\n05/05/2023 06:10:04 - INFO - datasets.builder - Using custom data configuration default-8c86fcb88e856ec9\\n05/05/2023 06:10:04 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\\n05/05/2023 06:10:04 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\\n05/05/2023 06:10:04 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-8c86fcb88e856ec9/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\n05/05/2023 06:10:04 - WARNING - datasets.builder - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-8c86fcb88e856ec9/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\\n05/05/2023 06:10:04 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-8c86fcb88e856ec9/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\n05/05/2023 06:10:05 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-8c86fcb88e856ec9/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-fa4cb601f916ff6c.arrow\\n05/05/2023 06:10:05 - INFO - __main__ - *** Predict ***\\n***** predict metrics *****\\n  predict_gen_len            =      114.0\\n  predict_loss               =     8.4926\\n  predict_rouge1             =        0.0\\n  predict_rouge2             =        0.0\\n  predict_rougeL             =        0.0\\n  predict_rougeLsum          =        0.0\\n  predict_runtime            = 0:00:04.00\\n  predict_samples            =          1\\n  predict_samples_per_second =       0.25\\n  predict_steps_per_second   =       0.25\\n\"\n"]}],"source":["# model.predict() function is used for prediction\n","# `test_path` :\n","# `output_path` :\n","# `model_name` :\n","# `model_type` :\n","# **kwargs : Additional arguments for the models\n","\n","#initializing the object for inference using pretrained model so that params get refreshed. params like learning rate etc modified for finetuning is not used.\n","pretrain_model = Summarizer(summary_type=\"table\")\n","\n","# Using predict function with necessary params\n","pretrain_model.predict(test_path=\"data/test_folder/processed/test_data.json\",output_path=\"table/prediction/test\", model_name=\"t5-small\",model_type=\"t5\")\n","\n","# Using predict function with additional params\n","# pretrain_model.predict(test_path=\"data/test_folder/processed/test_data.json\",output_path=\"table/prediction/test\",model_name=\"t5-small\",model_type=\"t5\",per_device_train_batch_size=2,learning_rate=5e-5,max_train_samples=50)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Y7hGWrnQw37h"},"source":["#### **Finetuned model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YSfAdU6tw9U2"},"outputs":[],"source":["# model.predict() function is used for prediction\n","# `test_path` :\n","# `output_path` :\n","# `model_name` :\n","# `model_type` :\n","# **kwargs : Additional arguments for the models\n","\n","# Using predict function with necessary params for finetuned model\n","model.predict(test_path=\"data/test_folder/processed/test_data.json\",output_path=\"table/prediction/test\", model_name=\"table/training\",model_type=\"t5\")\n","\n","## Using predict function with additional params\n","# model.predict(test_path=\"data/test_folder/processed/test_data.json\",output_path=\"table/prediction/test\",model_name=\"table/training\",model_type=\"t5\",per_device_train_batch_size=2,learning_rate=5e-5,max_train_samples=50)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"gRBi6DcXoVMD"},"source":["### **Using single context**\n","\n","We need to pass context as input and it extracts the summary for the given context.\n","\n","See the up-to-date list of [available models](https://huggingface.co/models?pipeline_tag=summarization)\n","\n","Below mentioned are some of the important points :\n","\n","* The user should provide the context as a string format.\n","\n","* We can pass pretrained / fine tuned model path. If the model name is not specified, default model(**facebook/bart-large-cnn**) is taken into consideration\n","\n","* If the model is t5  specifiy **model type =t5**, so that t5 params will get considered. else **model type = others**\n","\n","We can pass [**kwargs](https://huggingface.co/transformers/v3.0.2/main_classes/trainer.html#trainingarguments) to the predict function to alter the default model params."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ha0JT26YoVMI"},"outputs":[],"source":["context = \"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building,\"\\\n","\"and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side.\"\\\n","\"During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure\"\\\n","\"in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930.\"\\\n","\"It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top\"\\\n","\"of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, \"\\\n","\"the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\""]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"YfRjIgxbx36u"},"source":["#### **Pretrained model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pmpkXMmeoVMJ"},"outputs":[],"source":["# model.predict() function is used for prediction\n","# `context` :\n","# `model_name` :\n","# **kwargs : Additional arguments for the models\n","\n","#initializing the object for inference using pretrained model so that params get refreshed. params like learning rate etc modified for finetuning is not used.\n","pretrain_model = Summarizer(summary_type=\"table\")\n","\n","# Using predict function with necessary params\n","result=pretrain_model.predict(context=context,model_name=\"t5-small\",model_type=\"t5\")\n","\n","# Using predict function with additional params\n","# result=pretrain_model.predict(context=context,model_name=\"t5-small\",,model_type=\"t5\",learning_rate=5e-5,min_length=5, max_length=20)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"y_2xkL3PyMMX"},"source":["#### **Finetuned model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RhfjHQ9ayMMY"},"outputs":[],"source":["# model.predict() function is used for prediction\n","# `context` :\n","# `model_name` :\n","# **kwargs : Additional arguments for the models\n","\n","# Using predict function with necessary params\n","result=model.predict(context=context,model_name=\"table/training\",model_type=\"t5\")\n","\n","# Using predict function with additional params\n","# result=model.predict(context=context,model_name=\"table/training\",,model_type=\"t5\",learning_rate=5e-5,min_length=5, max_length=20)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"y8WFPCvGGlhF"},"source":["## **Evaluating Model**\n","\n","We can use the classical generative text evaluation metric like **BLEU**, **ROUGE** and **Semantic Similarity** scores to benchmark the model."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":360,"status":"ok","timestamp":1686661454855,"user":{"displayName":"Krishika Ragunathan","userId":"01566786126154607843"},"user_tz":-330},"id":"0t9yficn01IX","outputId":"2185e488-7352-43ec-e6b9-51af95744495"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-6f077ccc-c909-43cd-8c64-4034ed074a53\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>actual_summary</th>\n","      <th>predicted_summary</th>\n","      <th>model_name</th>\n","      <th>summary_type</th>\n","      <th>data_type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>&lt;table&gt; &lt;cell&gt; CHIPS_ DC SUMMIT IL &lt;header&gt; de...</td>\n","      <td>validation data table summary</td>\n","      <td>cell&gt; CHIPS_ DC SUMMIT IL header&gt; destination ...</td>\n","      <td>t5-small</td>\n","      <td>table</td>\n","      <td>train</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f077ccc-c909-43cd-8c64-4034ed074a53')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6f077ccc-c909-43cd-8c64-4034ed074a53 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6f077ccc-c909-43cd-8c64-4034ed074a53');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                text  \\\n","0  <table> <cell> CHIPS_ DC SUMMIT IL <header> de...   \n","\n","                  actual_summary  \\\n","0  validation data table summary   \n","\n","                                   predicted_summary model_name summary_type  \\\n","0  cell> CHIPS_ DC SUMMIT IL header> destination ...   t5-small        table   \n","\n","  data_type  \n","0     train  "]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["# specify prediction data path\n","path=\"table/prediction/test/\"\n","# reading predicted file\n","pred_df = open(path+'test_generated_predictions.jsonl')\n","pred_df = json.load(pred_df)\n","pred_df = pd.DataFrame(pred_df)\n","pred_df.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":942,"status":"ok","timestamp":1686661460400,"user":{"displayName":"Krishika Ragunathan","userId":"01566786126154607843"},"user_tz":-330},"id":"XG3C6vgDztN6","outputId":"1c8eaaa7-a142-470e-b839-ac6f9f77837e"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.0 0.05263157894736842 0.05263157894736842 0.15557736158370972\n"]}],"source":["# get_evaluation_metrics() function is used to generate benchmarking scores on different metrics\n","# `actuals` : Actual text or reference\n","# `predicted` : Generated text or predictions\n","\n","bleu,rouge_one,rouge_l,semantic,scores_df  =  get_evaluation_metrics(actuals=pred_df['actual_summary'].tolist(), predicted=pred_df['predicted_summary'].tolist())\n","scores_df.to_csv(os.path.join(path,\"metric_scores.csv\"))\n","print(bleu,rouge_one,rouge_l,semantic)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-1jeM6yRviXr"},"outputs":[],"source":[]}],"metadata":{"colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
